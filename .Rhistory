kk <- c(5, 10, 15, 20, 25, 28, 30, 40, 50, 60)
coherence_scores <- numeric(length(kk))
for (i in 1:length(kk)) {
model <- stm(houseDfmSTM$documents,
houseDfmSTM$vocab,
prevalence = ~ factor(company_type) + factor(year),
K = kk[i],
max.em.its = 200,
data = houseDfmSTM$meta,
init.type = "Spectral",
seed = 153332)
topics <- labelTopics(model)
topic_words <- topics$topic_words
# Calculate coherence for each topic
coherence <- numeric(kk[i])
for (j in 1:kk[i]) {
terms <- topic_words[[j]]
term_ids <- match(terms, houseDfmSTM$vocab)
beta <- model$beta[, term_ids]
prob_w_in_d <- as.matrix(houseDfmSTM$documents[, term_ids]) / colSums(houseDfmSTM$documents)
coherence[j] <- sum(beta * log((beta + 1e-10) / (prob_w_in_d + 1e-10)))
}
# Average coherence scores for all topics
coherence_scores[i] <- mean(coherence)
}
library(stm)
library(tm)
kk <- c(5, 10, 15, 20, 25, 28, 30, 40, 50, 60)
coherence_scores <- numeric(length(kk))
for (i in 1:length(kk)) {
model <- stm(houseDfmSTM$documents,
houseDfmSTM$vocab,
prevalence = ~ factor(company_type) + factor(year),
K = kk[i],
max.em.its = 200,
data = houseDfmSTM$meta,
init.type = "Spectral",
seed = 153332)
topics <- labelTopics(model)
topic_words <- topics$topic_words
# Calculate coherence for each topic
coherence <- numeric(kk[i])
for (j in 1:kk[i]) {
terms <- topic_words[[j]]
term_ids <- match(terms, houseDfmSTM$vocab)
# Extract beta values for selected terms in the current topic
beta_for_terms <- model$beta[j, term_ids]
# Calculate coherence for the current topic
coherences_for_terms <- numeric(length(term_ids))
for (k in 1:length(term_ids)) {
term_id <- term_ids[k]
coherences_for_terms[k] <- sum(log((beta_for_terms[k] + 1e-10) /
(model$beta[, term_id] + 1e-10)))
}
coherence[j] <- sum(coherences_for_terms) / length(term_ids)
}
# Average coherence scores for all topics
coherence_scores[i] <- mean(coherence)
}
library(stm)
library(tm)
kk <- c(5, 10, 15, 20, 25, 28, 30, 40, 50, 60)
coherence_scores <- numeric(length(kk))
for (i in 1:length(kk)) {
model <- stm(houseDfmSTM$documents,
houseDfmSTM$vocab,
prevalence = ~ factor(company_type) + factor(year),
K = kk[i],
max.em.its = 200,
data = houseDfmSTM$meta,
init.type = "Spectral",
seed = 153332)
topics <- labelTopics(model)
topic_words <- topics$topic_words
# Calculate coherence for each topic
coherence <- numeric(kk[i])
for (j in 1:kk[i]) {
terms <- topic_words[[j]]
term_ids <- match(terms, houseDfmSTM$vocab)
# Extract beta values for selected terms in the current topic
beta_for_terms <- model$theta[ , j] / sum(model$theta[ , j])
beta_for_terms <- beta_for_terms[term_ids]
# Calculate coherence for the current topic
coherences_for_terms <- numeric(length(term_ids))
for (k in 1:length(term_ids)) {
term_id <- term_ids[k]
coherences_for_terms[k] <- sum(log((beta_for_terms[k] + 1e-10) /
(model$theta[ , term_id] / sum(model$theta[ , term_id]) + 1e-10)))
}
coherence[j] <- sum(coherences_for_terms) / length(term_ids)
}
# Average coherence scores for all topics
coherence_scores[i] <- mean(coherence)
}
# Find the index of the model with the highest coherence score
best_model_index <- which.max(coherence_scores)
# Get the ideal number of topics
ideal_num_topics <- kk[best_model_index]
# Print and visualize the coherence scores
print(coherence_scores)
plot(kk, coherence_scores, type = "b", xlab = "Number of Topics", ylab = "Coherence Score")
labelTopics(model_stm[[1]])
labelTopics(model_stm[[1]])
model_stm[[1]]$theta
model_stm[[1]]$settings$covariates
labelTopics(model_stm[[1]])
library(stm)
coherence_scores <- lapply(model_stm, function(model) {
stm_coherence(model)
})
coherence_scores <- lapply(model_stm, function(model) {
stmCoherence(model)
})
coherence_scores <- lapply(model_stm, function(model) {
semanticCoherence(model)
})
coherence_scores <- lapply(model_stm, function(model) {
semanticCoherence(model, documents)
})
View(coherence_scores)
library(ggplot2)
coherence_df <- data.frame(K = kk, Coherence = unlist(coherence_scores))
coherence_df <- data.frame(K = kk, Coherence = sapply(coherence_scores, function(score) score$average_coherence))
coherence_values <- sapply(coherence_scores, function(score) score$coherence)
coherence_df <- data.frame(K = kk, Coherence = coherence_scores)
coherence_scores <- lapply(model_stm, function(model) {
semanticCoherence(model, documents)
})
coherence_df <- data.frame(K = kk, Coherence = coherence_scores)
coherence_df <- data.frame(K = kk, Coherence = unlist(coherence_scores))
coherence_df <- data.frame(K = kk, Coherence = unlist(coherence_scores))
coherence_df <- data.frame(K = kk, Coherence = sapply(coherence_scores, function(score) mean(score$semanticCoherence)))
coherence_scores <- lapply(model_stm, function(model) {
coherence_score <- semanticCoherence(model, documents)
return(coherence_score$score)
})
average_coherence_per_model <- sapply(coherence_scores, mean)
# Print the average coherence scores
print(average_coherence_per_model)
labelTopics(model_stm[[2])
labelTopics(model_stm[[2]])
labelTopics(model_stm[[6]])
library(stm)
# Split your dataset into training and testing sets
set.seed(123)  # For reproducibility
sample_indices <- sample(1:nrow(houseDfmSTM$documents), size = 0.8 * nrow(houseDfmSTM$documents))
# Split your dataset into training and testing sets
set.seed(123)  # For reproducibility
sample_indices <- sample(1:nrow(documents), size = 0.8 * nrow(documents))
sample_indices <- sample(1:nrow(llDisplay), size = 0.8 * nrow(documents))
labelTopics(model_stm[[6]])
labelTopics(model_stm[[2]])
coherence_scores[[2]]
labelTopics(model_stm[[1]])
labelTopics(model_stm[[2]])
coherence_scores[[2]]
labelTopics(model_stm[[3]])
coherence_scores[[3]]
coherence_scores[[10]]
labelTopics(model_stm[[1]])
labelTopics(model_stm[[2]])
coherence_scores[[2]]
labelTopics(model_stm[[3]])
model_stm[[1]]$theta
model_stm[[1]]$settings$covariates
model_stm[[1]]$theta
model_stm[[1]]$settings$covariates # covariates
labelTopics(model_stm[[3]])
coherence_scores[[3]]
labelTopics(model_stm[[4]])
coherence_scores[[4]]
labelTopics(model_stm[[8]])
coherence_scores[[8]]
labelTopics(model_stm[[1]])
coherence_scores[[1]]
labelTopics(model_stm[[2]])
labelTopics(model_stm[[1]])
labelTopics(model_stm[[3]])
labelTopics(model_stm[[4]])
labelTopics(model_stm[[5]])
coherence_scores[[5]]
labelTopics(model_stm[[6]])
coherence_scores[[6]]
labelTopics(model_stm[[7]])
labelTopics(model_stm[[4]])
labelTopics(model_stm[[4]])
model_stm[[4]]$theta
model_stm[[4]]$settings$covariates
labelTopics(model_stm[[4]]) # FREX = frequent + not shared by other topics
model_stm[[4]]$theta
model_stm[[4]]$theta[, '5']
model_stm[[4]]$theta[, 5]
x = model_stm[[4]]$theta[, 5]
y = model_stm[[4]]$theta
x = model_stm[[4]]$theta[, 5]
model_stm[[4]]$theta[, 5]
model_stm[[4]]$theta[, 14]
model_stm[[4]]$theta
model_stm[[4]]$theta
model_stm[[4]]$theta[, 14]
model_stm[[4]]$settings$covariates
View(textData)
model_stm[[4]]$settings$covariates # covariates
topic_proportions <- model_stm[[4]]$theta[, 5]
metadata_variable <- data$company_type
metadata_variable <- model_stm$company_type
correlation_matrix <- cor(topic_proportions, metadata_variable)
correlations <- sapply(topic_proportions, function(topic) cor(topic, metadata_variable))
correlations <- sapply(topic_proportions, function(topic) cor(topic, metadata_variable))
# Extract topic proportions from the model
topic_proportions <- model_stm$theta  # Replace with the actual topic proportions
# Extract the metadata variable from your data
metadata_variable <- model_stm$company_type  # Replace with the actual column name
correlations <- c()
for (i in 1:nrow(topic_proportions)) {
topic_proportion <- topic_proportions[i, ]
metadata_value <- company_type[i]
correlation <- cor(topic_proportion, company_type)
correlations <- c(correlations, correlation)
}
doc_topic_matrix <- model_stm[[4]]$theta
# Extract the metadata variable from your data
metadata_variable <- data$company_type  # Replace with the actual column name
doc_topic_matrix <- model_stm[[4]]$theta
# Extract the metadata variable from your data
metadata_variable <- data$company_type  # Replace with the actual column name
# Extract document-topic matrix from the model
doc_topic_matrix <- model_stm[[4]]$theta
# Extract the metadata variable from your data
metadata_variable <- model_stm$company_type  # Replace with the actual metadata column name
# Initialize a vector to store correlations
correlations <- numeric()
# Loop through each document
for (i in 1:nrow(doc_topic_matrix)) {
document_topic_probs <- doc_topic_matrix[i, ]
correlation <- cor(document_topic_probs, company_type[i])
correlations <- c(correlations, correlation)
}
# Extract document-topic matrix from the model
doc_topic_matrix <- model_stm[[4]]$theta
# Extract the metadata variable from your data
metadata_variable <- textData$company_type  # Replace with the actual metadata column name
# Initialize a vector to store correlations
correlations <- numeric()
# Loop through each document
for (i in 1:nrow(doc_topic_matrix)) {
document_topic_probs <- doc_topic_matrix[i, ]
correlation <- cor(document_topic_probs, metadata_variable[i])
correlations <- c(correlations, correlation)
}
combined_data <- cbind(doc_topic_matrix, metadata_variable)
# Extract document-topic matrix from the model
doc_topic_matrix <- model_stm[[4]]$theta
# Extract the metadata variable from your data
metadata_variable <- textData$company_type  # Replace with the actual metadata column name
# Combine doc_topic_matrix and metadata_variable
combined_data <- cbind(doc_topic_matrix, metadata_variable)
# Calculate the average topic proportions for each category
average_topic_proportions <- aggregate(. ~ metadata_variable, data = combined_data, FUN = mean)
metadata_variable <- textData$company_type  # Replace with the actual metadata column name
textData$company_type
num_documents <- nrow(model_stm[[4]]$theta)
num_topics <- ncol(model_stm[[4]]$theta)
nrow(model_stm[[4]]$theta)
ncol(model_stm[[4]]$theta)
# Step 1: Ensure dimensions match
num_documents <- nrow(model_stm[[4]]$theta)
num_topics <- ncol(model_stm[[4]]$theta)
# Step 2: Extract and prepare data
document_ids <- rownames(model_stm[[4]]$theta)
company_types <- textData$company_type[match(document_ids, textData$document_id_column)]
correlations <- numeric(num_topics)
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
correlations[topic_idx] <- cor(topic_proportions, company_types)
}
# Step 1: Ensure dimensions match
num_documents <- nrow(model_stm[[4]]$theta)
num_topics <- ncol(model_stm[[4]]$theta)
# Step 2: Extract and prepare data
document_ids <- rownames(model_stm[[4]]$theta)
company_types <- textData$company_type[match(document_ids, textData$document_id_column)]
# Convert company_types to a factor
company_types_factor <- as.factor(company_types)
# Step 3: Calculate correlations
correlations <- numeric(num_topics)
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
# Convert the factor to numeric representation for correlation calculation
company_types_numeric <- as.numeric(company_types_factor)
correlations[topic_idx] <- cor(topic_proportions, company_types_numeric)
}
# Convert company_types to a factor
company_types_factor <- as.factor(company_types)
# Create a matrix to store mean topic proportions for each company type
mean_topic_proportions <- matrix(0, nlevels(company_types_factor), num_topics)
# Loop through each topic and calculate mean topic proportions for each company type
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
# Aggregate topic proportions by company type
for (company_type_level in levels(company_types_factor)) {
company_topic_proportions <- topic_proportions[company_types_factor == company_type_level]
mean_topic_proportions[company_type_level, topic_idx] <- mean(company_topic_proportions)
}
}
print(mean_topic_proportions)
View(mean_topic_proportions)
View(mean_topic_proportions)
# Step 1: Ensure dimensions match
num_documents <- nrow(model_stm[[4]]$theta)
num_topics <- ncol(model_stm[[4]]$theta)
# Step 2: Extract and prepare data
document_ids <- rownames(model_stm[[4]]$theta)
company_types <- textData$company_type[match(document_ids, textData$document_id_column)]
correlations <- numeric(num_topics)
View(correlations)
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
company_types_numeric = -1
if (company_types == "energy") {
company_types_numeric = 0
} else if (company_types == "clean-energy") {
company_types_numeric = 1
}
correlations[topic_idx] <- cor(topic_proportions, company_types_numeric)
}
company_types
company_types <- textData$company_type[match(document_ids, textData$document_id_column)]
company_types
textData$company_type
company_types <- textData$company_type
# Step 3: Calculate correlations
correlations <- numeric(num_topics)
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
company_types_numeric = -1
if (company_types == "energy") {
company_types_numeric = 0
} else if (company_types == "clean-energy") {
company_types_numeric = 1
}
correlations[topic_idx] <- cor(topic_proportions, company_types_numeric)
}
textData$company_type[match(document_ids, textData$document_id_column)]
textData$company_ticker
model_stm[[4]]$theta
topic_proportions <- model_stm[[4]]$theta
metadata_variable <- textData$env_capex
# Step 1: Ensure dimensions match
num_documents <- nrow(model_stm[[4]]$theta)
num_topics <- ncol(model_stm[[4]]$theta)
env_capexs = textData$env_capex[match(document_ids, textData$document_id_column)]
num_topics <- ncol(model_stm[[4]]$theta)
env_capexs = textData$env_capex[match(document_ids, textData$document_id_column)]
correlations <- numeric(num_topics)
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
correlations[topic_idx] <- cor(topic_proportions, env_capexs)
}
textData$env_capex[match(document_ids, textData$document_id_column)]
textData$env_capex
model_stm[[4]]$theta
# correlate the green columns of theta (the topics) with the capex data
topic_proportions <- model_stm[[4]]$theta
metadata_variable <- textData$env_capex
# TODO: correlate here
num_topics <- ncol(model_stm[[4]]$theta)
env_capexs = textData$env_capex[match(document_ids, textData$document_id_column)]
correlations <- numeric(num_topics)
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
correlations[topic_idx] <- cor(topic_proportions, env_capexs)
}
print(length(topic_proportions))
print(length(env_capexs))
env_capexs = textData$env_capex#[match(document_ids, textData$document_id_column)]
print(length(topic_proportions))
print(length(env_capexs))
correlations <- numeric(num_topics)
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
correlations[topic_idx] <- cor(topic_proportions, env_capexs)
}
correlations
percentage = textData$env_capex / textData$capex
percentage
100 * textData$env_capex / textData$capex
percentage = round(100 * textData$env_capex / textData$capex, digits = 0)
percentage
topic_proportions <- model_stm[[4]]$theta
percentages = round(100 * textData$env_capex / textData$capex, digits = 0)
num_topics <- ncol(model_stm[[4]]$theta)
correlations <- numeric(num_topics)
topic_proportions <- model_stm[[4]]$theta
topic_proportions
num_documents <- nrow(textData)
num_topics <- ncol(model_stm[[4]]$theta)
correlations <- matrix(0, nrow = num_documents, ncol = num_topics)
for (doc_idx in 1:num_documents) {
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[doc_idx, topic_idx]
percentage <- percentages[doc_idx]
correlations[doc_idx, topic_idx] <- cor(topic_proportions, percentage)
}
}
correlations
num_documents <- nrow(textData)
num_topics <- ncol(model_stm[[4]]$theta)
correlations <- matrix(0, nrow = num_documents, ncol = num_topics)
for (doc_idx in 1:num_documents) {
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[doc_idx, topic_idx]
percentage <- percentages[doc_idx]
if (topic_proportions != 0 && percentage != 0) {
correlations[doc_idx, topic_idx] <- cor(topic_proportions, percentage)
}
}
}
num_documents <- nrow(textData)
num_topics <- ncol(model_stm[[4]]$theta)
correlations <- matrix(0, nrow = num_documents, ncol = num_topics)
for (doc_idx in 1:num_documents) {
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[doc_idx, topic_idx]
percentage <- percentages[doc_idx]
# Check if either value is zero before calculating the correlation
if (topic_proportions != 0 && percentage != 0) {
correlations[doc_idx, topic_idx] <- cor(topic_proportions, percentage)
}
}
}
num_documents <- nrow(textData)
num_topics <- ncol(model_stm[[4]]$theta)
correlations <- matrix(0, nrow = num_documents, ncol = num_topics)
for (doc_idx in 1:num_documents) {
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[doc_idx, topic_idx]
percentage <- percentages[doc_idx]
# Check if either value is zero before calculating the correlation
if (!is.na(topic_proportions) && !is.na(percentage) && topic_proportions != 0 && percentage != 0) {
correlations[doc_idx, topic_idx] <- cor(topic_proportions, percentage)
}
}
}
correlations
View(correlations)
print(correlations)
library(ggplot2)
variable_names <- c("topic_proportions", "percentages")
correlations <- c(0.8, 0.5)
correlation_data <- data.frame(
Variable = variable_names,
Correlation = correlations
)
ggplot(data = correlation_data, aes(x = Variable, y = Correlation)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Correlation between Variables",
x = "Variables",
y = "Correlation") +
theme_minimal()
company_data <- data.frame(
Company = c("Company A", "Company B", "Company C", "Company D", "Company E"),
Topic_Probability = c(0.8, 0.6, 0.4, 0.7, 0.9),
Env_Capex_Percentage = c(15, 20, 10, 25, 30)
)
ggplot(company_data, aes(x = Env_Capex_Percentage, y = Topic_Probability)) +
geom_point() +
labs(title = "Topic Probability vs. Env Capex Percentage",
x = "Environmental Capex Percentage",
y = "Topic Probability") +
theme_minimal()
Adjust the aesthetics, labels, and other plot components as needed to customize the appearance of the scatterplot according to your preferences. This code assumes you want a basic scatterplot. You can further enhance it by adding regression lines, adjusting point colors, adding labels, and so on.
company_data <- data.frame(
Company = c("Company A", "Company B", "Company C", "Company D", "Company E"),
Topic_Probability = c(0.8, 0.6, 0.4, 0.7, 0.9),
Env_Capex_Percentage = c(15, 20, 10, 25, 30)
)
ggplot(company_data, aes(x = Env_Capex_Percentage, y = Topic_Probability)) +
geom_point() +
labs(title = "Topic Probability vs. Env Capex Percentage",
x = "Environmental Capex Percentage",
y = "Topic Probability") +
theme_minimal()
company_data <- data.frame(
Company = c("agr", "arry", "cop", "cvx", "cwen"),
Topic_Probability = c(0.8, 0.6, 0.4, 0.7, 0.9),
Env_Capex_Percentage = c(15, 20, 10, 25, 30)
)
ggplot(company_data, aes(x = Env_Capex_Percentage, y = Topic_Probability)) +
geom_point() +
labs(title = "Topic Probability vs. Env Capex Percentage",
x = "Environmental Capex Percentage",
y = "Topic Probability") +
theme_minimal()
ggplot(company_data, aes(x = Env_Capex_Percentage, y = Topic_Probability)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +
labs(title = "Topic Probability vs. Env Capex Percentage",
x = "Environmental Capex Percentage",
y = "Topic Probability") +
theme_minimal()
data_set_with_topics_and_metadata<- data_set_with_topics_and_metadata %>%group_by(ticker) %>%summarise_all(mean(topics))
lm(financial_1~topic1)
topic_proportions <- model_stm[[4]]$theta
capex_percentages = round(100 * textData$env_capex / textData$capex, digits = 0)
num_topics <- ncol(model_stm[[4]]$theta)
correlations <- numeric(num_topics)
for (topic_idx in 1:num_topics) {
topic_proportions <- model_stm[[4]]$theta[, topic_idx]
correlations[topic_idx] <- cor(topic_proportions, capex_percentages)
}
correlations
